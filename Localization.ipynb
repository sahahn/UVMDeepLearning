{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from skimage import feature\n",
    "import matplotlib.pyplot as plt\n",
    "import keras, random, os\n",
    "import keras.utils\n",
    "from keras import losses\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv3D, MaxPooling3D\n",
    "from keras.layers import Input, Embedding, Activation\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from sklearn.neighbors.kde import KernelDensity\n",
    "from scipy import stats\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_labels():\n",
    "    with open('labels.csv', 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    label_dict = {}\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.split(',')\n",
    "        \n",
    "        file = line[0].split('/')[-1]\n",
    "        file = file.split('.')[0]\n",
    "        \n",
    "        label_dict[file] = []\n",
    "        \n",
    "        for coord in line[1:]:\n",
    "            label_dict[file].append(float(coord))     \n",
    "    \n",
    "    return label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_dict = get_labels()\n",
    "\n",
    "directory = 'data/'\n",
    "files = os.listdir(directory)\n",
    "files = [file for file in files if '.npy' in file]\n",
    "\n",
    "scans = []\n",
    "edges = []\n",
    "labels = []\n",
    "#scans = np.asarray(scans)\n",
    "\n",
    "for file in files:\n",
    "    name = file.split('.')[0]\n",
    "    \n",
    "    scan = np.load(directory+file)\n",
    "    edge = np.array([feature.canny(slc, sigma=1) for slc in scan])\n",
    "    label = label_dict[name]\n",
    "    \n",
    "    scans.append(scan)\n",
    "    edges.append(edge)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "canidates = []\n",
    "num_per_sample = 208\n",
    "num_near_true = 25\n",
    "\n",
    "#MAX = 0\n",
    "#MIN = 0\n",
    "\n",
    "val_split = 40\n",
    "\n",
    "for e in range(len(edges)):\n",
    "    \n",
    "    history = set()\n",
    "    shape = np.shape(edges[e])  \n",
    "    \n",
    "    for i in range(num_per_sample):\n",
    "        valid = False\n",
    "\n",
    "        while not valid:\n",
    "            r1 = random.randint(0,shape[0]-33) #z\n",
    "            r2 = random.randint(0,shape[1]-33) #x\n",
    "            r3 = random.randint(0,shape[2]-33) #y\n",
    "            \n",
    "            if e <= val_split:\n",
    "                if i == 0:\n",
    "                    r1 = int(labels[e][2])\n",
    "                    r2 = int(labels[e][0])\n",
    "                    r3 = int(labels[e][1])\n",
    "\n",
    "                elif i == num_near_true:\n",
    "                    r1 = int(labels[e][5])\n",
    "                    r2 = int(labels[e][3])\n",
    "                    r3 = int(labels[e][4])\n",
    "\n",
    "                #Get within say 6\n",
    "                elif i > 0 and i < num_near_true:\n",
    "                    r1 = random.randint(int(labels[e][2])-3, int(labels[e][2])+3) #z\n",
    "                    r2 = random.randint(int(labels[e][0])-3, int(labels[e][0])+3) #x\n",
    "                    r3 = random.randint(int(labels[e][1])-3, int(labels[e][1])+3) #y\n",
    "\n",
    "                elif i > num_near_true and i < 2*num_near_true:\n",
    "\n",
    "                    r1 = random.randint(int(labels[e][5])-3, int(labels[e][5])+3) #z\n",
    "                    r2 = random.randint(int(labels[e][3])-3, int(labels[e][3])+3) #x\n",
    "                    r3 = random.randint(int(labels[e][4])-3, int(labels[e][4])+3) #y\n",
    "\n",
    "                while r1 < 0:\n",
    "                    r1 += 1\n",
    "                while r1 > shape[0]-33:\n",
    "                    r1 -= 1\n",
    "                while r2 < 0:\n",
    "                    r2 += 1\n",
    "                while r2 > shape[1]-33:\n",
    "                    r2 -= 1\n",
    "                while r3 < 0:\n",
    "                    r3 += 1\n",
    "                while r3 > shape[2]-33:\n",
    "                    r3 -= 1\n",
    "            \n",
    "            coord = (r1,r2,r3)\n",
    "            \n",
    "        \n",
    "            if (edges[e][r1][r2][r3] and coord not in history) or (e <= val_split and i < 2*num_near_true):\n",
    "                history.add(coord)\n",
    "                \n",
    "                dif = np.array([labels[e][0] - r2, labels[e][1] - r3, labels[e][2] - r1, labels[e][3] - r2,\n",
    "                               labels[e][4] - r3, labels[e][5] - r1])\n",
    "                \n",
    "                #m = np.max(dif)\n",
    "                #m2 = np.min(dif)\n",
    "                \n",
    "                #if m > MAX:\n",
    "                #    MAX = m\n",
    "                    \n",
    "                #if m2 < MIN:\n",
    "                #    MIN = m2\n",
    "                \n",
    "                #So each canidate in the list contains the refrence scan #, the coord to sample, and the 6 dif points\n",
    "                canidate = [e, coord, dif]\n",
    "                \n",
    "                canidates.append(canidate)\n",
    "                \n",
    "                valid = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sample_from(i):\n",
    "    '''Takes in an index from the canidate list, and returns the label and the cropped scan in x'''\n",
    "    \n",
    "    s = canidates[i][0]\n",
    "    coord = canidates[i][1]\n",
    "    label = canidates[i][2]\n",
    "    \n",
    "    #Try normalizing the labels\n",
    "    #label -= MIN\n",
    "    #label /= (MAX-MIN)\n",
    "    \n",
    "    #Coord is in z,x,y like scans, but labels are x,y,z\n",
    "    return np.expand_dims((scans[s][coord[0]:coord[0]+32, coord[1]:coord[1]+32, coord[2]:coord[2]+32]), axis=3), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, list_IDs, batch_size=16, dim=(32,32,32),\n",
    "             n_classes=6, shuffle=True):\n",
    "        \n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    " \n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "    \n",
    "        if self.shuffle == True:\n",
    "            \n",
    "            #Just shuffle the order for each CT\n",
    "            for i in range(len(self.indexes) // num_per_sample):\n",
    "                np.random.shuffle(self.indexes[i*num_per_sample:(i+1)*num_per_sample])\n",
    "            \n",
    "            #np.random.shuffle(self.indexes)\n",
    "            \n",
    "            \n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "\n",
    "        X = np.empty((self.batch_size, *self.dim, 1))\n",
    "        y = np.empty((self.batch_size, 1, 1, 1, self.n_classes), dtype=float)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            \n",
    "            X[i], y[i] = get_sample_from(ID)\n",
    "    \n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'dim': (32,32,32),\n",
    "          'batch_size': 16,\n",
    "          'n_classes': 6,\n",
    "          'shuffle': True}\n",
    "\n",
    "train = [i for i in range(val_split*num_per_sample)]\n",
    "validation = [i for i in range(val_split*num_per_sample,len(canidates))]\n",
    "\n",
    "training_generator = DataGenerator(train, **params)\n",
    "validation_generator = DataGenerator(validation, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def localization_net():\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv3D(filters=64, kernel_size=(3, 3, 3), padding='same', input_shape=(32, 32, 32, 1)))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv3D(filters=64, kernel_size=(3, 3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='same'))\n",
    "\n",
    "    model.add(Conv3D(filters=128, kernel_size=(3, 3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv3D(filters=128, kernel_size=(3, 3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='same'))\n",
    "\n",
    "    model.add(Conv3D(filters=256, kernel_size=(3, 3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv3D(filters=256, kernel_size=(3, 3, 3), padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='same'))\n",
    "\n",
    "    model.add(Conv3D(filters=512, kernel_size=(4, 4, 4), padding='valid'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "\n",
    "    model.add(Conv3D(filters=512, kernel_size=(1, 1, 1), padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "\n",
    "    model.add(Conv3D(filters=6, kernel_size=(1, 1, 1), padding='same'))\n",
    "    #model.add(BatchNormalization(axis=-1))\n",
    "\n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iou_loss(y_true, y_pred):\n",
    "    # iou loss for bounding box prediction\n",
    "    # input is [x1, y1, z1, x2, y2, z2]\n",
    "\n",
    "    \n",
    "    x1_t = (K.transpose(y_true)[0])# * (MAX-MIN))\n",
    "    y1_t = (K.transpose(y_true)[1])# * (MAX-MIN))\n",
    "    z1_t = (K.transpose(y_true)[2])# * (MAX-MIN))\n",
    "    x2_t = (K.transpose(y_true)[3])# * (MAX-MIN))\n",
    "    y2_t = (K.transpose(y_true)[4])# * (MAX-MIN))\n",
    "    z2_t = (K.transpose(y_true)[5])# * (MAX-MIN))\n",
    "    \n",
    "    x1_p = (K.transpose(y_pred)[0])# * (MAX-MIN))\n",
    "    y1_p = (K.transpose(y_pred)[1])# * (MAX-MIN))\n",
    "    z1_p = (K.transpose(y_pred)[2])# * (MAX-MIN))\n",
    "    x2_p = (K.transpose(y_pred)[3])# * (MAX-MIN))\n",
    "    y2_p = (K.transpose(y_pred)[4])# * (MAX-MIN))\n",
    "    z2_p = (K.transpose(y_pred)[5])# * (MAX-MIN))\n",
    "\n",
    "    # AOG = Area of Groundtruth box\n",
    "    AoG = K.abs(x2_t - x1_t + 1) * K.abs(y2_t - y1_t + 1) * K.abs(z2_t - z1_t + 1)\n",
    "    \n",
    "    # AOP = Area of Predicted box\n",
    "    AoP = K.abs(x2_p - x1_p + 1) * K.abs(y2_p - y1_p + 1) * K.abs(z2_p - z1_p + 1)\n",
    "    \n",
    "    \n",
    "    #print(K.eval(AoG))\n",
    "    #print(K.eval(AoP))\n",
    "    # overlaps are the co-ordinates of intersection box\n",
    "    \n",
    "    overlap_0 = K.maximum(x1_t, x1_p)\n",
    "    overlap_1 = K.maximum(y1_t, y1_p)\n",
    "    overlap_2 = K.maximum(z1_t, z1_p)\n",
    "    overlap_3 = K.minimum(x2_t, x2_p)\n",
    "    overlap_4 = K.minimum(y2_t, y2_p)\n",
    "    overlap_5 = K.minimum(z2_t, z2_p)\n",
    "    \n",
    "    x = (overlap_3 - overlap_0 + 1)\n",
    "    y = (overlap_4 - overlap_1 + 1)\n",
    "    z = (overlap_5 - overlap_2 + 1)\n",
    "    \n",
    "    x = K.clip(x, 0.0, 1000000)\n",
    "    y = K.clip(y, 0.0, 1000000)\n",
    "    z = K.clip(z, 0.0, 1000000)\n",
    "    \n",
    "    intersection = x*y*z\n",
    "    \n",
    "    # area of union of both boxes\n",
    "    union = AoG + AoP - intersection\n",
    "    \n",
    "    # iou calculation\n",
    "    iou = intersection / union\n",
    "\n",
    "    # bounding values of iou to (0,1)\n",
    "    iou = K.clip(iou, 0.0 + K.epsilon(), 1.0 - K.epsilon())\n",
    "\n",
    "    # loss for the iou value\n",
    "    iou_loss = -K.log(iou)\n",
    "\n",
    "    return iou_loss\n",
    "\n",
    "def iou_metric(y_true, y_pred):\n",
    "    # iou loss for bounding box prediction\n",
    "    # input is [x1, y1, z1, x2, y2, z2]\n",
    "  \n",
    "    x1_t = (K.transpose(y_true)[0])# * (MAX-MIN)) + MIN\n",
    "    y1_t = (K.transpose(y_true)[1])# * (MAX-MIN)) + MIN\n",
    "    z1_t = (K.transpose(y_true)[2])# * (MAX-MIN)) + MIN\n",
    "    x2_t = (K.transpose(y_true)[3])# * (MAX-MIN)) + MIN\n",
    "    y2_t = (K.transpose(y_true)[4])# * (MAX-MIN)) + MIN\n",
    "    z2_t = (K.transpose(y_true)[5])# * (MAX-MIN)) + MIN\n",
    "    \n",
    "    x1_p = (K.transpose(y_pred)[0])# * (MAX-MIN)) + MIN\n",
    "    y1_p = (K.transpose(y_pred)[1])# * (MAX-MIN)) + MIN\n",
    "    z1_p = (K.transpose(y_pred)[2])# * (MAX-MIN)) + MIN\n",
    "    x2_p = (K.transpose(y_pred)[3])# * (MAX-MIN)) + MIN\n",
    "    y2_p = (K.transpose(y_pred)[4])# * (MAX-MIN)) + MIN\n",
    "    z2_p = (K.transpose(y_pred)[5])# * (MAX-MIN)) + MIN\n",
    "\n",
    "    # AOG = Area of Groundtruth box\n",
    "    AoG = K.abs(x2_t - x1_t + 1) * K.abs(y2_t - y1_t + 1) * K.abs(z2_t - z1_t + 1)\n",
    "    \n",
    "    # AOP = Area of Predicted box\n",
    "    AoP = K.abs(x2_p - x1_p + 1) * K.abs(y2_p - y1_p + 1) * K.abs(z2_p - z1_p + 1)\n",
    "    \n",
    "    \n",
    "    #print(K.eval(AoG))\n",
    "    #print(K.eval(AoP))\n",
    "    # overlaps are the co-ordinates of intersection box\n",
    "    \n",
    "    overlap_0 = K.maximum(x1_t, x1_p)\n",
    "    overlap_1 = K.maximum(y1_t, y1_p)\n",
    "    overlap_2 = K.maximum(z1_t, z1_p)\n",
    "    overlap_3 = K.minimum(x2_t, x2_p)\n",
    "    overlap_4 = K.minimum(y2_t, y2_p)\n",
    "    overlap_5 = K.minimum(z2_t, z2_p)\n",
    "    \n",
    "    x = (overlap_3 - overlap_0 + 1)\n",
    "    y = (overlap_4 - overlap_1 + 1)\n",
    "    z = (overlap_5 - overlap_2 + 1)\n",
    "    \n",
    "    x = K.clip(x, 0.0, 1000000)\n",
    "    y = K.clip(y, 0.0, 1000000)\n",
    "    z = K.clip(z, 0.0, 1000000)\n",
    "    \n",
    "    intersection = x*y*z\n",
    "    \n",
    "    # area of union of both boxes\n",
    "    union = AoG + AoP - intersection\n",
    "    \n",
    "    # iou calculation\n",
    "    iou = intersection / union\n",
    "\n",
    "    # bounding values of iou to (0,1)\n",
    "    iou = K.clip(iou, 0.0 + K.epsilon(), 1.0 - K.epsilon())\n",
    "    \n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = localization_net()\n",
    "#model.compile(loss=iou_loss, optimizer='adam', metrics = [iou_metric])\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics = [iou_metric])\n",
    "model.load_weights('weights.hdf5')\n",
    "\n",
    "#model = load_model('model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint('/tmp/weights.hdf5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "520/520 [==============================] - 842s 2s/step - loss: 246.8859 - iou_metric: 0.3260 - val_loss: 320.4315 - val_iou_metric: 0.3581\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 320.43146, saving model to /tmp/weights.hdf5\n",
      "Epoch 2/10\n",
      "520/520 [==============================] - 863s 2s/step - loss: 238.1950 - iou_metric: 0.3206 - val_loss: 301.9840 - val_iou_metric: 0.3764\n",
      "\n",
      "Epoch 00002: val_loss improved from 320.43146 to 301.98398, saving model to /tmp/weights.hdf5\n",
      "Epoch 3/10\n",
      "519/520 [============================>.] - ETA: 1s - loss: 222.5183 - iou_metric: 0.3262"
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator=training_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    use_multiprocessing=True, workers=6, epochs=10, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.save('model1.h5')\n",
    "model.save_weights(\"weights.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = localization_net()\n",
    "model.compile(loss=iou_loss, optimizer='adam', metrics = [iou_metric])\n",
    "#model.compile(loss='mean_squared_error', optimizer='adam', metrics = [iou_metric])\n",
    "model.load_weights('weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(generator=training_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    use_multiprocessing=True, workers=6, epochs=20, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_point(predictions, to_pred):\n",
    "    \n",
    "    \n",
    "    #print(predictions)\n",
    "    \n",
    "    #return np.round(np.mean(samples, axis=0))\n",
    "    \n",
    "    #o_dist = 10\n",
    "    #sh = np.shape(edges[to_pred])\n",
    "\n",
    "    #T = [pred for pred in predictions if pred[0] > -o_dist and pred[1] > -o_dist and pred[2] > -o_dist]\n",
    "    #T = [pred for pred in T if pred[0] < sh[1]+o_dist and pred[1] < sh[2]+o_dist and pred[2] < sh[0]+o_dist]\n",
    "    \n",
    "    T=predictions\n",
    "    \n",
    "    kde = KernelDensity(kernel='gaussian', bandwidth=0.2).fit(T)\n",
    "    samples = kde.sample(n_samples=10000)\n",
    "    \n",
    "    #p = stats.mode(np.round(samples))[0][0]\n",
    "    #print(p)\n",
    "    p = np.mean(samples, axis=0)\n",
    "    \n",
    "    #print(p)\n",
    "    return np.round(p)\n",
    "\n",
    "def IoU(tl1,br1,tl2,br2):\n",
    "\n",
    "    xA = max(tl1[0], tl2[0])\n",
    "    yA = max(tl1[1], tl2[1])\n",
    "    zA = max(tl1[2], tl2[2])\n",
    "    \n",
    "    xB = min(br1[0], br2[0])\n",
    "    yB = min(br1[1], br2[1])\n",
    "    zB = min(br1[2], br2[2])\n",
    "\n",
    "    x = (xB - xA + 1)\n",
    "    y = (yB - yA + 1)\n",
    "    z = (zB - zA + 1)\n",
    "    \n",
    "    if (x < 0 or y < 0 or z < 0):\n",
    "        return 0\n",
    "    \n",
    "    interArea = x*y*z\n",
    " \n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (br1[0]-tl1[0]+1) * (br1[1]-tl1[1]+1) * (br1[2]-tl1[2]+1)\n",
    "    boxBArea = (br2[0]-tl2[0]+1) * (br2[1]-tl2[1]+1) * (br2[2]-tl2[2]+1)\n",
    "\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    " \n",
    "    # return the intersection over union value\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def n(x):\n",
    "    return (x - MIN) / (MAX-MIN)\n",
    "\n",
    "def r(x):\n",
    "    return (x*(MAX-MIN))-MIN\n",
    "\n",
    "\n",
    "label1 = np.array([-2.0,1.0,1.0,6.0,5.0,7.0])\n",
    "label2 = np.array([2.0,4.0,3.0,6.0,6.0,7.0])\n",
    "label1 -= MIN\n",
    "label1 /= (MAX-MIN)\n",
    "\n",
    "label2 -= MIN\n",
    "label2 /= (MAX-MIN)\n",
    "\n",
    "\n",
    "#print(label1)\n",
    "#print((-2-MIN) / (MAX-MIN))\n",
    "\n",
    "\n",
    "#print(IoU([-2.0,1.0,1.0],[6.0,5.0,7.0],[2.0,4.0,3.0],[6.0,6.0,7.0]))\n",
    "#x= iou_metric(label1, label2)\n",
    "\n",
    "#K.eval(x) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(to_pred):\n",
    "    params = {'dim': (32,32,32),\n",
    "              'batch_size': 10,\n",
    "              'n_classes': 6,\n",
    "              'shuffle': False}\n",
    "\n",
    "    test = [x for x in range(to_pred*num_per_sample,(to_pred+1)*num_per_sample)]\n",
    "    test_generator = DataGenerator(test, **params)\n",
    "    predicted = model.predict_generator(test_generator)\n",
    "    \n",
    "    #Predicted points are scaled to / MAX so, bring them back to scale\n",
    "    #predicted *= (MAX-MIN)\n",
    "    #predicted += MIN\n",
    "    \n",
    "    predictionsTL = []\n",
    "    predictionsBR = []\n",
    "\n",
    "    #The actual labels...\n",
    "    actualTL = [labels[to_pred][0], labels[to_pred][1], labels[to_pred][2]]\n",
    "    actualBR = [labels[to_pred][3], labels[to_pred][4], labels[to_pred][5]]\n",
    "\n",
    "    c = to_pred*num_per_sample\n",
    "    for i in range(len(predicted)):\n",
    "\n",
    "        #Get the coordinate of the guess\n",
    "        coords = canidates[c+i][1]\n",
    "        coord = np.array([coords[1],coords[2],coords[0]])\n",
    "        \n",
    "        tl,br = [],[]\n",
    "\n",
    "        #Grab the predicted displacment vector for each point\n",
    "        for y in range(6):\n",
    "            if y < 3:\n",
    "                tl.append(predicted[i][0][0][0][y])\n",
    "            else:\n",
    "                br.append(predicted[i][0][0][0][y])\n",
    "\n",
    "        #Add the predictions as actual point + displacment\n",
    "        predictionsTL.append(coord + np.array(tl))\n",
    "        predictionsBR.append(coord + np.array(br))\n",
    "        \n",
    "        #print(IoU(coord+np.array(tl), coord+np.array(br), actualTL, actualBR))\n",
    "\n",
    "        \n",
    "    pTL = predict_point(predictionsTL, to_pred)\n",
    "    dist1 = np.linalg.norm(pTL-actualTL)\n",
    "\n",
    "    pTR = predict_point(predictionsBR, to_pred)\n",
    "    dist2 = np.linalg.norm(pTR-actualBR)\n",
    "\n",
    "    return dist1, dist2, IoU(pTL,pTR,actualTL,actualBR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dist1s = []\n",
    "dist2s = []\n",
    "ious = []\n",
    "\n",
    "for i in range(40,59):\n",
    "    d1,d2,u = predict(i)\n",
    "    \n",
    "    dist1s.append(d1)\n",
    "    dist2s.append(d2)\n",
    "    ious.append(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(np.mean(dist1s))\n",
    "print(np.mean(dist2s))\n",
    "print(np.mean(ious))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
